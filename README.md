# InformaÃ§Ãµes Hospitalares â€“ Pipeline de Engenharia de Dados

Projeto completo de engenharia de dados utilizando dados pÃºblicos do SIH-SUS (Sistema de InformaÃ§Ãµes Hospitalares do SUS).

O projeto implementa uma arquitetura moderna baseada em Data Lake com camadas **Bronze, Silver e Gold**, utilizando Docker para garantir reprodutibilidade do ambiente.

---

## Objetivo

Construir um pipeline completo de dados que:

- Realiza download automatizado dos dados do SIH

- Armazena os dados brutos na camada Bronze (MinIO)

- Realiza transformaÃ§Ãµes com Spark (Silver)

- Aplica enriquecimentos e modelagem analÃ­tica (Gold)

- Publica dados no PostgreSQL

- Disponibiliza visualizaÃ§Ã£o via Metabase

---

## ğŸ§± Arquitetura

SIH (Download)
      â†“
Bronze (MinIO - Parquet)
      â†“
Silver (Delta Lake particionado por ano/mÃªs)
      â†“
Gold (Delta Lake modelado para anÃ¡lise)
      â†“
PostgreSQL
      â†“
Metabase Dashboard

## Stack Utilizada

- Apache Spark 3.5

- Delta Lake

- MinIO (S3 Compatible)

- PostgreSQL

- Metabase

- Docker & Docker Compose

- PySpark

- boto3

## ğŸ“ Estrutura do Projeto

```
Informacoes_hospitalares/
â”œâ”€â”€ notebooks/              # Scripts PySpark (.ipynb)
â”œâ”€â”€ .envÂ Â Â Â Â Â Â Â Â Â Â Â Â Â       # ConfiguraÃ§Ã£o
â”œâ”€â”€ docker-compose.yml      # Infraestrutura local
â”œâ”€â”€ data/                   # Arquivos auxiliares (ex: CSV de CID-10)
â”œâ”€â”€ docs/                   # Print do dashboard
â””â”€â”€ README.md               # Este arquivo
```

---

## â–¶ï¸ Como Executar Localmente

> PrÃ©-requisitos:
> 
> - Docker e Docker Compose
> - Git
> - PySpark (caso rode localmente fora do container)



1. **Clone o repositÃ³rio:**

```bash
git clone https://github.com/mafreitas85/Informacoes_hospitalares.git
cd Informacoes_hospitalares
```

2. **Suba o ambiente:**

```bash
docker compose up -d
```

Isso irÃ¡ subir:

- Spark Master

- Spark Worker

- MinIO

- PostgreSQL

- Metabase



3. **Acesse os serviÃ§os:**
   
   
- **MinIO**: http://localhost:9001  
  Login: `admin` | Senha: `SenhaForte123!`

- **Metabase**: http://localhost:3000  
  Login: definido na primeira configuraÃ§Ã£o

- **PostgreSQL**: `localhost:5432`  
  UsuÃ¡rio: `admin` | Senha: `SenhaForte123!` | Banco: `my_database`



4. **Preparar o Data Lake**

Â Â Â Â Â Â Â Â Execute dentro do container do Jupyter:

```bash
docker exec -it spark_jupyter bash
python Scripts/setup_lake.pyIsso irÃ¡:
```

- Criar bucket datalake

- Criar estrutura Bronze/Silver/Gold

- Enviar arquivos auxiliares



5. **Download dos Dados**
   
   ```bash
   python Scripts/download_sih.py
   ```

Isso farÃ¡:

- Download dos dados SIH

- Envio automÃ¡tico para a camada Bronze



6. **Processamento Bronze â†’ Silver**

```bash
python Scripts/01_bronze_to_silver.py
```

Gera:

- Delta Lake particionado por ano e mÃªs



7. **Processamento Silver â†’ Gold**

```bash
python Scripts/02_silver_to_gold.py
```

Gera:

- Dataset enriquecido

- Escrita na camada Gold

- PublicaÃ§Ã£o no PostgreSQL



## ğŸ“Š Dashboard

O dashboard foi criado no Metabase, explorando os principais motivos de internaÃ§Ã£o no estado de SP.

> ğŸ“· Um print do dashboard serÃ¡ incluÃ­do na pasta `/docs`.



Link metabase: http://localhost:3000



Configure conexÃ£o PostgreSQL:

- Host: postgres_lab

- Porta: 5432

- Banco: postgres

- UsuÃ¡rio: admin

- Senha: SenhaForte123!

---

## ğŸ‘¤ Autor

**Marcos Freitas Alves**  
[LinkedIn](https://www.linkedin.com/in/marcos-freitas-alves)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob os termos da licenÃ§a MIT.